# 데이터 및 훈련 관련 설정
data :
  train_data_path : '/data/ephemeral/home/data/train/DCM'
  train_label_path : '/data/ephemeral/home/data/train/outputs_json'
  test_data_path : '/data/ephemeral/home/data/test/DCM'
  classes : [
    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',
    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',
    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',
    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',
    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',
    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',
  ]

  fold : 0
  split_method : GroupKFold


  train : 
    batch_size : 4
    shuffle : True
    num_workers : 2
    pin_memory : True
    drop_last : True
    print_step: 20
    ratio : 0.8
    early_stopping_patience : 5
    early_stopping_delta : 0.001
    max_epoch : 100
    

  valid : 
    batch_size : 4
    shuffle : False
    num_workers : 2
    pin_memory : True
    drop_last : False
    interval: 10  # validation 및 체크포인트 저장 주기
    threshold: 0.5

    interpolate:
      nearest: 'nearest'
      bilinear: 'bilinear'
      bicubic: 'bicubic'
      area: 'area'
      lanczos: 'lanczos'

  

  test : 
    batch_size : 4
    shuffle : False
    num_workers : 2
    pin_memory : True
    drop_last : False
  

augmentation:
  train:
    - Resize:
        height: 512
        width: 512
    - Rotate:
        limit: 10
        p: 0.5
    - CLAHE:
        clip_limit: 4.0
        tile_grid_size: [8, 8]  
        p: 0.5
    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    

  valid:
    - Resize:
        height: 512
        width: 512
    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

  test :
    - Resize:
        height: 1024
        width: 1024
    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

save:
  # 실험 config 저장 경로
  save_config: /data/ephemeral/home/level2-cv-semanticsegmentation-cv-22-lv3/configs
  # 체크포인트 저장 경로
  save_ckpt: /data/ephemeral/home/level2-cv-semanticsegmentation-cv-22-lv3/checkpoints


seed: 42


loss_func: 
  # BCEWithLogitsLoss, DiceLoss, JaccardLoss, FocalLoss
  name: BCEWithLogitsLoss

loss_func_defaults:
  BCEWithLogitsLoss: {}
  DiceLoss:
    mode: multilabel
  JaccardLoss:
    mode: multilabel
  FocalLoss:
    mode: multilabel
    alpha: 0.25
    gamma: 0.2    


optimizer: 
  name: AdamW
  params:
    lr: 1e-4
    weight_decay: 1e-2
    betas: [0.9, 0.999]
    eps: 1e-08
    amsgrad: false

optimizer_defaults:
  Adam:
    lr: 1e-4
    weight_decay: 1e-6
  SGD:
    lr: 1e-4
    momentum: 0.9
    weight_decay: 1e-6
  AdamW:
    lr: 1e-4
    weight_decay: 1e-2  # AdamW는 weight_decay를 상대적으로 더 크게 설정하는 것이 일반적
  RMSprop:
    lr: 1e-4
    alpha: 0.99        # smoothing constant
    momentum: 0.9
    weight_decay: 1e-6
  Adagrad:
    lr: 1e-2           # Adagrad는 보통 비교적 큰 학습률로 시작
    weight_decay: 1e-6
    initial_accumulator_value: 0.1
  Adadelta:
    lr: 1.0            # Adadelta는 보통 기본값이 1.0
    rho: 0.9           # decay rate
    eps: 1e-6
    weight_decay: 0    # 일반적으로 Adadelta는 weight_decay를 사용하지 않음


scheduler:
  # CosineAnnealingLR, StepLR, ReduceLROnPlateau, ExponentialLR, MultiStepLR, CosineAnnealingWarmRestarts
  name: CosineAnnealingLR
  params:
    T_max: 50

scheduler_defaults:
  CosineAnnealingLR:
    T_max: 100
    eta_min: 0        # default
    last_epoch: -1    # default
  StepLR:
    step_size: 20
    gamma: 0.1
    last_epoch: -1
  ReduceLROnPlateau:
    mode: min
    factor: 0.1
    patience: 10
    threshold: 0.0001
    cooldown: 0
    min_lr: 0
    eps: 1e-8
  ExponentialLR:
    gamma: 0.1
    last_epoch: -1
  MultiStepLR:
    # 특정 에폭에서 학습률을 감소
    milestones: [30, 60, 90]
    gamma: 0.1
    last_epoch: -1
  CosineAnnealingWarmRestarts:
    # 학습률을 코사인 곡선을 따라 감소시키다가 설정된 주기마다 다시 초기 학습률로 "재시작"하는 방식
    T_0: 10           # 첫 번째 주기의 길이
    T_mult: 1         # 각 주기마다 늘리는 비율
    eta_min: 0        # 학습률이 도달할 수 있는 최저값
    last_epoch: -1    # 스케줄러가 몇 번째 epoch에서 시작해야 하는지 


# 디버깅 모드
debug: False


# Inference 관련 설정
inference:
  threshold: 0.5
  output_size: [2048, 2048]  # 튜플을 리스트로 수정
  checkpoint_path: "/data/ephemeral/home/level2-cv-semanticsegmentation-cv-22-lv3/checkpoints/lraspp_mobilenet/lraspp_mobilenet_v3_large_best_model.pt"  # .ckpt에서 .pt로 수정
  output_dir: "/data/ephemeral/home/level2-cv-semanticsegmentation-cv-22-lv3/results"