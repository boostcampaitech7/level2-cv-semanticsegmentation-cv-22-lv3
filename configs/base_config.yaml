# 데이터 및 훈련 관련 설정
data :
  train_data_path : '../../data/train/DCM'
  train_label_path : '../../data/train/outputs_json'
  test_data_path : '../../data/test/DCM'


  classes : [
    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',
    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',
    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',
    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',
    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',
    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',
]

  fold : 0
  split_method : GroupKFold
  splits : 5


  train : 
    batch_size : 2
    shuffle : True
    num_workers : 8
    pin_memory : True
    drop_last : True
    print_step: 20
    ratio : 0.8
    early_stopping_patience : 5
    early_stopping_delta : 0.001
    max_epoch : 100
    decline_score : 0.3
    

  valid : 
    batch_size : 2
    shuffle : False
    num_workers : 8
    pin_memory : True
    drop_last : False
    interval: 10  
    threshold: 0.5
    check: True
  

  test : 
    batch_size : 2
    shuffle : False
    num_workers : 8
    pin_memory : True
    drop_last : False



inference:
  threshold: 0.5
  output_size: [2048, 2048] 
  checkpoint_path: "../checkpoints/best_model.pt"  # .ckpt에서 .pt로 수정
  output_dir: "../results"
  mode: 'gpu'



interpolate:
    nearest: 'nearest'
    bilinear: 'bilinear'
    bicubic: 'bicubic'
    area: 'area'
    lanczos: 'lanczos'
  

augmentation:
  train:
    - HorizontalFlip: {}
    - GridDistortion:
        p: 0.3
        num_steps: 5
        distort_limit:
        - -0.3
        - 0.3
        
    - Resize:
        height: 1024
        width: 1024

    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
  
  valid:
    - Resize:
        height: 1024
        width: 1024

    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

  test:
    - Resize:
        height: 1024
        width: 1024

    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]


loss_func: 
  weight_map : True
  # loss_func: BCEWithLogitsLoss, DiceLoss, JaccardLoss, FocalLoss, 
  #            CombinedWeightedLoss, TwoWayLoss, BCEDiceLoss
  name: CombinedWeightedLoss

loss_func_defaults:
  BCEWithLogitsLoss: {}
  DiceLoss:
    mode: multilabel
  JaccardLoss:
    mode: multilabel
  FocalLoss:
    mode: multilabel
    alpha: 0.25
    gamma: 0.2   
  CombinedWeightedLoss:
    weight_inside: 1.0
    weight_boundary: 2.0
  TwoWayLoss:
    Tp: 4.0
    Tn: 1.0
  BCEDiceLoss:
    dice_mode: multilabel



optimizer: 
  # optimizer: Adam, SGD, AdamW, RMSprop, Adagrad, Adadelta
  name: AdamW
  params:
    lr: 1e-4

optimizer_defaults:
  Adam:
    lr: 1e-4
    weight_decay: 1e-6
  SGD:
    lr: 1e-4
    momentum: 0.9
    weight_decay: 1e-6
  AdamW:
    lr: 1e-4
    weight_decay: 1e-2  
  RMSprop:
    lr: 1e-4
    alpha: 0.99       
    momentum: 0.9
    weight_decay: 1e-6
  Adagrad:
    lr: 1e-2          
    weight_decay: 1e-6
    initial_accumulator_value: 0.1
  Adadelta:
    lr: 1.0            
    rho: 0.9          
    eps: 1e-6
    weight_decay: 0   


scheduler:
  # scheduler: CosineAnnealingLR, StepLR, ReduceLROnPlateau, 
  #            ExponentialLR, MultiStepLR, CosineAnnealingWarmRestarts
  name: CosineAnnealingLR
  params:
    T_max: 50

scheduler_defaults:
  CosineAnnealingLR:
    T_max: 100
    eta_min: 0       
    last_epoch: -1   
  StepLR:
    step_size: 20
    gamma: 0.1
    last_epoch: -1
  ReduceLROnPlateau:
    mode: min
    factor: 0.1
    patience: 10
    threshold: 0.0001
    cooldown: 0
    min_lr: 0
    eps: 1e-8
  ExponentialLR:
    gamma: 0.1
    last_epoch: -1
  MultiStepLR:
    milestones: [30, 60, 90]
    gamma: 0.1
    last_epoch: -1
  CosineAnnealingWarmRestarts:
    T_0: 10          
    T_mult: 1        
    eta_min: 0       
    last_epoch: -1    



debug: True
save:
  save_config: ../configs
  save_ckpt: ../checkpoints

seed: 42